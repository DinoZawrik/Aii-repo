{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) - Sentiment Analysis\n",
    "\n",
    "**Автор:** Новиков Максим Петрович  \n",
    "**Группа:** БСБО-05-23\n",
    "\n",
    "В этом ноутбуке проводится разведочный анализ данных для задачи анализа тональности текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Настройки отображения\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "df = pd.read_csv('../data/sentiment_data.csv')\n",
    "\n",
    "print(f\"Размер датасета: {df.shape[0]} строк, {df.shape[1]} столбцов\")\n",
    "print(f\"\\nСтолбцы: {list(df.columns)}\")\n",
    "print(f\"\\nТипы данных:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первые 10 строк\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Базовая статистика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на пропуски\n",
    "print(\"Пропущенные значения:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nДубликаты: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение классов\n",
    "label_counts = df['label'].value_counts()\n",
    "print(\"Распределение классов:\")\n",
    "print(f\"Положительные (1): {label_counts[1]} ({label_counts[1]/len(df)*100:.1f}%)\")\n",
    "print(f\"Отрицательные (0): {label_counts[0]} ({label_counts[0]/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация распределения классов\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "bars = ax.bar(['Negative (0)', 'Positive (1)'], label_counts.values, color=colors)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of Sentiment Classes')\n",
    "\n",
    "# Добавляем числа на столбцы\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            str(count), ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/class_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Анализ текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Длина текстов\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"Статистика по длине текста (символы):\")\n",
    "print(df['text_length'].describe())\n",
    "\n",
    "print(\"\\nСтатистика по количеству слов:\")\n",
    "print(df['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределение длины текста по классам\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# По количеству символов\n",
    "for label, color in zip([0, 1], colors):\n",
    "    subset = df[df['label'] == label]['text_length']\n",
    "    label_name = 'Positive' if label == 1 else 'Negative'\n",
    "    axes[0].hist(subset, bins=20, alpha=0.7, label=label_name, color=color)\n",
    "axes[0].set_xlabel('Text Length (characters)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of Text Length by Sentiment')\n",
    "axes[0].legend()\n",
    "\n",
    "# По количеству слов\n",
    "for label, color in zip([0, 1], colors):\n",
    "    subset = df[df['label'] == label]['word_count']\n",
    "    label_name = 'Positive' if label == 1 else 'Negative'\n",
    "    axes[1].hist(subset, bins=15, alpha=0.7, label=label_name, color=color)\n",
    "axes[1].set_xlabel('Word Count')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Distribution of Word Count by Sentiment')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/text_length_distribution.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя длина текста по классам\n",
    "print(\"Средняя длина текста по классам:\")\n",
    "print(df.groupby('label')[['text_length', 'word_count']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Анализ часто встречающихся слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Очистка текста для анализа слов\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def get_word_freq(texts):\n",
    "    \"\"\"Подсчёт частоты слов\"\"\"\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        words = clean_text(text).split()\n",
    "        all_words.extend(words)\n",
    "    return Counter(all_words)\n",
    "\n",
    "# Частота слов для каждого класса\n",
    "positive_texts = df[df['label'] == 1]['text']\n",
    "negative_texts = df[df['label'] == 0]['text']\n",
    "\n",
    "positive_freq = get_word_freq(positive_texts)\n",
    "negative_freq = get_word_freq(negative_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Топ-15 слов для каждого класса\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Положительные\n",
    "top_positive = dict(positive_freq.most_common(15))\n",
    "axes[0].barh(list(top_positive.keys())[::-1], list(top_positive.values())[::-1], color='#4ECDC4')\n",
    "axes[0].set_xlabel('Frequency')\n",
    "axes[0].set_title('Top 15 Words in Positive Reviews')\n",
    "\n",
    "# Отрицательные\n",
    "top_negative = dict(negative_freq.most_common(15))\n",
    "axes[1].barh(list(top_negative.keys())[::-1], list(top_negative.values())[::-1], color='#FF6B6B')\n",
    "axes[1].set_xlabel('Frequency')\n",
    "axes[1].set_title('Top 15 Words in Negative Reviews')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../artifacts/word_frequency.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Примеры текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Примеры ПОЛОЖИТЕЛЬНЫХ отзывов:\")\n",
    "print(\"-\" * 50)\n",
    "for text in df[df['label'] == 1]['text'].sample(5, random_state=42).values:\n",
    "    print(f\"• {text}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Примеры ОТРИЦАТЕЛЬНЫХ отзывов:\")\n",
    "print(\"-\" * 50)\n",
    "for text in df[df['label'] == 0]['text'].sample(5, random_state=42).values:\n",
    "    print(f\"• {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Выводы по EDA\n",
    "\n",
    "### Основные наблюдения:\n",
    "\n",
    "1. **Размер данных:** Датасет содержит 100 отзывов - достаточно для демонстрации.\n",
    "\n",
    "2. **Баланс классов:** Классы идеально сбалансированы (50/50) - не требуется применение техник балансировки.\n",
    "\n",
    "3. **Качество данных:** Нет пропущенных значений и дубликатов.\n",
    "\n",
    "4. **Длина текстов:** Средняя длина ~45-50 символов, ~8-9 слов. Тексты короткие и однородные.\n",
    "\n",
    "5. **Ключевые слова:**\n",
    "   - Положительные: \"love\", \"great\", \"amazing\", \"excellent\", \"perfect\"\n",
    "   - Отрицательные: \"terrible\", \"awful\", \"horrible\", \"worst\", \"disappointed\"\n",
    "\n",
    "### Рекомендации для моделирования:\n",
    "\n",
    "1. Использовать TF-IDF для baseline модели (LogisticRegression)\n",
    "2. Для улучшенной модели - DistilBERT как легковесный трансформер\n",
    "3. Метрики: Accuracy, Precision, Recall, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение статистики\n",
    "import os\n",
    "os.makedirs('../artifacts', exist_ok=True)\n",
    "\n",
    "stats = {\n",
    "    'total_samples': len(df),\n",
    "    'positive_samples': int(label_counts[1]),\n",
    "    'negative_samples': int(label_counts[0]),\n",
    "    'avg_text_length': float(df['text_length'].mean()),\n",
    "    'avg_word_count': float(df['word_count'].mean())\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../artifacts/eda_stats.json', 'w') as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "print(\"EDA статистика сохранена в artifacts/eda_stats.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
